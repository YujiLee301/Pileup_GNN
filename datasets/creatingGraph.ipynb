{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e68f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from math import pi\n",
    "import torch\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "import pickle\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c966c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f80ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select pfcands from original root and convert to a dataframe'\n",
    "def gen_dataframe(num_event, num_start=0):\n",
    "    print(f\"reading events from {num_start} to {num_start+num_event}\")\n",
    "    tree = uproot.open(\n",
    "        \"/depot/cms/private/users/gpaspala/output_1.root\")[\"Events\"]\n",
    "    pfcands = tree.arrays(\n",
    "        tree.keys('PF_*'), entry_start=num_start, entry_stop=num_event + num_start)\n",
    "    \n",
    "    print (tree.num_entries)\n",
    "\n",
    "    df_list = []\n",
    "    #\n",
    "    # todo: this loop can probably be removed\n",
    "    #\n",
    "    for i in range(num_event):\n",
    "        event = pfcands[i]\n",
    "        # eliminate those with eta more than 2.5\n",
    "        eta_eliminate = abs(event['PF_eta']) < 2.5\n",
    "        event = event[eta_eliminate]\n",
    "        #\n",
    "        # todo: add more features here\n",
    "        #\n",
    "        selected_features = ['PF_eta', 'PF_phi', 'PF_pt', \n",
    "                             'PF_pdgId', 'PF_charge', 'PF_puppiWeight','PF_dz']\n",
    "        event_nPF = ak.to_numpy(event['PF_eta']).size\n",
    "        pf_chosen = event[selected_features]\n",
    "\n",
    "        df_pfcands = ak.to_pandas(pf_chosen)\n",
    "        #df_pfcands['PF_pt'] = np.log(df_pfcands['PF_pt'])\n",
    "        df_list.append(df_pfcands)\n",
    "\n",
    "    return df_list\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd577d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(num_event, num_start=0):\n",
    "    data_list = []\n",
    "\n",
    "    df_list = gen_dataframe(num_event, num_start)\n",
    "\n",
    "    PTCUT = 0.5\n",
    "\n",
    "    for num in range(len(df_list)):\n",
    "        if num % 100 == 0:\n",
    "            print(f\"processed {num} events\")\n",
    "        #\n",
    "        # toDO: this for loop can probably be also removed\n",
    "        # and the gen_dataframe can be merged inside this function\n",
    "        #\n",
    "        df_pfcands = df_list[num]\n",
    "        LV_index = df_pfcands[(df_pfcands['PF_puppiWeight'] > 0.99) & (df_pfcands['PF_charge'] != 0) & (\n",
    "            df_pfcands['PF_pt'] > PTCUT)].index.codes[0]\n",
    "        PU_index = df_pfcands[(df_pfcands['PF_puppiWeight'] < 0.01) & (df_pfcands['PF_charge'] != 0) & (\n",
    "            df_pfcands['PF_pt'] > PTCUT)].index.codes[0]\n",
    "        #print(\"LV index\", LV_index)\n",
    "        #print(\"PU index\", PU_index)\n",
    "        if LV_index.shape[0] < 5 or PU_index.shape[0] < 50:\n",
    "            continue\n",
    "        Neutral_index = df_pfcands[(\n",
    "            df_pfcands['PF_charge'] == 0)].index.codes[0]\n",
    "        Charge_index = df_pfcands[(\n",
    "            df_pfcands['PF_charge'] != 0)].index.codes[0]\n",
    "\n",
    "        # label of samples\n",
    "        label = df_pfcands.loc[:, ['PF_puppiWeight']].to_numpy()\n",
    "        label = torch.from_numpy(label).view(-1)\n",
    "        label = label.type(torch.long)\n",
    "\n",
    "        # node features\n",
    "        node_features = df_pfcands.drop(\n",
    "            df_pfcands.loc[:, ['PF_charge']], axis=1).to_numpy()\n",
    "       \n",
    "        node_features = torch.from_numpy(node_features)\n",
    "        node_features = node_features.type(torch.float32)\n",
    "\n",
    "        # set the charge pdgId for one hot encoding later\n",
    "        node_features[[Charge_index.tolist()], 3] = 0\n",
    "        # get index for mask training and testing samples for pdgId(3) and puppiWeight(4)\n",
    "        # one hot encoding for pdgId and puppiWeight\n",
    "        pdgId = node_features[:, 3]\n",
    "        photon_indices = (pdgId == 22)\n",
    "        pdgId[photon_indices] = 1\n",
    "        hadron_indices = (pdgId == 130)\n",
    "        pdgId[hadron_indices] = 2\n",
    "        pdgId = pdgId.type(torch.long)\n",
    "        pdgId_one_hot = torch.nn.functional.one_hot(pdgId)\n",
    "        pdgId_one_hot = pdgId_one_hot.type(torch.float32)\n",
    "\n",
    "        # set the neutral puppiWeight to default\n",
    "        node_features[[Neutral_index.tolist()], 4] = 2\n",
    "        puppiWeight = node_features[:, 4]\n",
    "        puppiWeight = puppiWeight.type(torch.long)\n",
    "        puppiWeight_one_hot = torch.nn.functional.one_hot(puppiWeight)\n",
    "        puppiWeight_one_hot = puppiWeight_one_hot.type(torch.float32)\n",
    "        columnsNamesArr = df_pfcands.columns.values\n",
    "        \n",
    "         \n",
    "        node_features = torch.cat(\n",
    "            #(node_features[:, 0:3], pdgId_one_hot, puppiWeight_one_hot), 1)\n",
    "            (node_features[:, 0:3], pdgId_one_hot,node_features[:,5:6], puppiWeight_one_hot), 1)\n",
    "            # (node_features[:, 0:4], pdgId_one_hot, puppiWeight_one_hot), 1)\n",
    "\n",
    "        if num == 0:\n",
    "            print(\"pdgId dimensions: \", pdgId_one_hot.shape)\n",
    "            print(\"puppi weights dimensions: \", puppiWeight_one_hot.shape)\n",
    "            print(\"node_features dimension: \", node_features.shape)\n",
    "            print(\"columnsNamesArr\", columnsNamesArr)\n",
    "            #print(\"node features: \", node_features)\n",
    "\n",
    "        # node_features = node_features.type(torch.float32)\n",
    "        # construct edge index for graph\n",
    "\n",
    "        phi        = df_pfcands['PF_phi'].to_numpy().reshape((-1, 1))\n",
    "        eta        = df_pfcands['PF_eta'].to_numpy().reshape((-1, 1))\n",
    "        #vertexChi2 = df_pfcands['PF_vertexChi2'].to_numpy().reshape((-1, 1))\n",
    "        #mass       = df_pfcands['PF_mass'].to_numpy().reshape((-1, 1))\n",
    "        dz         = df_pfcands['PF_dz'].to_numpy().reshape((-1, 1))\n",
    "        #d0         = df_pfcands['PF_d0'].to_numpy().reshape((-1, 1))\n",
    "        #vertexNdof = df_pfcands['PF_vertexNdof'].to_numpy().reshape((-1, 1))\n",
    "        #fromPV     = df_pfcands['PF_fromPV'].to_numpy().reshape((-1, 1))\n",
    "        #trkChi2 = df_pfcands['PF_trkChi2'].to_numpy().reshape((-1, 1))\n",
    "        #vertexNormalizedChi2 = df_pfcands['PF_vertexNormalizedChi2'].to_numpy().reshape((-1, 1))\n",
    "        charge= df_pfcands['PF_charge'].to_numpy().reshape((-1, 1))\n",
    "\n",
    "        #PF_hasTrackDetails = df_pfcand['PF_hasTrackDetails'].to_numpy().reshape((-1, 1))\n",
    "       # print (\"phi\", phi)\n",
    "        #print (\"PF_fromPV\", fromPV)\n",
    "        #print (\"PF_trkChi2\",trkChi2)\n",
    "        #print (\"PF_vertexNormalizedChi2\",vertexNormalizedChi2)\n",
    "        #print (\"vertexNdof\",vertexNdof)\n",
    "       # print (\"PF_d0\", d0)\n",
    "        #print (\"PF_dz\", dz)\n",
    "       # print (\"PF_charge\", charge)\n",
    "       # print (\"PF_vertexChi2\",vertexChi2)\n",
    "        \n",
    "        \n",
    "\n",
    "        dist_phi = distance.cdist(phi, phi, 'cityblock')\n",
    "        # deal with periodic feature of phi\n",
    "        indices = np.where(dist_phi > pi)\n",
    "        temp = np.ceil((dist_phi[indices] - pi) / (2 * pi)) * (2 * pi)\n",
    "        dist_phi[indices] = dist_phi[indices] - temp\n",
    "        dist_eta = distance.cdist(eta, eta, 'cityblock')\n",
    "\n",
    "        dist = np.sqrt(dist_phi ** 2 + dist_eta ** 2)\n",
    "        edge_source = np.where((dist < 0.4) & (dist != 0))[0]\n",
    "        edge_target = np.where((dist < 0.4) & (dist != 0))[1]\n",
    "\n",
    "        edge_index = torch.tensor([edge_source, edge_target], dtype=torch.long)\n",
    "\n",
    "        graph = Data(x=node_features, edge_index=edge_index, y=label)\n",
    "        graph.LV_index = LV_index\n",
    "        graph.PU_index = PU_index\n",
    "        graph.Neutral_index = Neutral_index\n",
    "        graph.Charge_index = Charge_index\n",
    "        graph.num_classes = 2\n",
    "        data_list.append(graph)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77487279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start = timer()\n",
    "    num_events_train = 100\n",
    "    dataset_train = prepare_dataset(num_events_train)\n",
    "    with open(\"dataset_graph_puppi_\" + str(num_events_train), \"wb\") as fp:\n",
    "        pickle.dump(dataset_train, fp)\n",
    "\n",
    "    num_events_valid = 50\n",
    "    dataset_valid = prepare_dataset(num_events_valid, num_events_train)\n",
    "    with open(\"dataset_graph_puppi_\" + str(num_events_valid), \"wb\") as fp:\n",
    "        pickle.dump(dataset_valid, fp)\n",
    "\n",
    "\n",
    "    end = timer()\n",
    "    program_time = end - start\n",
    "    print(\"generating graph time \" + str(program_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34ae238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading events from 0 to 100\n",
      "2000\n",
      "processed 0 events\n",
      "pdgId dimensions:  torch.Size([331, 3])\n",
      "puppi weights dimensions:  torch.Size([331, 3])\n",
      "node_features dimension:  torch.Size([331, 10])\n",
      "columnsNamesArr ['PF_eta' 'PF_phi' 'PF_pt' 'PF_pdgId' 'PF_charge' 'PF_puppiWeight' 'PF_dz']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2571860/594278957.py:114: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  edge_index = torch.tensor([edge_source, edge_target], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading events from 100 to 150\n",
      "2000\n",
      "processed 0 events\n",
      "pdgId dimensions:  torch.Size([1050, 3])\n",
      "puppi weights dimensions:  torch.Size([1050, 3])\n",
      "node_features dimension:  torch.Size([1050, 10])\n",
      "columnsNamesArr ['PF_eta' 'PF_phi' 'PF_pt' 'PF_pdgId' 'PF_charge' 'PF_puppiWeight' 'PF_dz']\n",
      "generating graph time 259.5884099723771\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660c263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
